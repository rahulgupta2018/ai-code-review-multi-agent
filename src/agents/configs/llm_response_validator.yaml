# LLM Response Validator Configuration
# Configuration for quality control, bias prevention, and hallucination detection in LLM responses

version: "1.0.0"

# Validation thresholds and scoring parameters
validation_thresholds:
  # Content validation
  content_validation:
    min_response_length: 50
    max_jargon_count: 3
    max_confident_statements: 2
    max_pattern_words: 3
    max_method_references: 5
    max_technical_claims: 3
  
  # Confidence scoring
  confidence_scoring:
    base_confidence_max: 0.5
    content_length_divisor: 1000
    evidence_confidence_max: 0.3
    evidence_multiplier: 0.05
    specificity_confidence_max: 0.2
    specificity_multiplier: 0.02
    uncertainty_penalty_max: 0.2
    uncertainty_multiplier: 0.05
  
  # Evidence scoring
  evidence_scoring:
    min_findings_score: 0.3
    min_metrics_score: 0.3
    code_reference_multiplier: 0.05
    reasoning_multiplier: 0.04
    reasoning_max_score: 0.2
  
  # Quality gates
  quality_gates:
    min_response_length: 20
    min_confidence_threshold: 0.6
    min_evidence_threshold: 0.3

# Bias detection patterns and indicators
bias_detection:
  # Language bias patterns
  language_preferences:
    - "python is better"
    - "javascript is superior"  
    - "java is outdated"
    - "golang is faster"
    - "rust is safer"
    - "typescript is cleaner"
  
  # Confirmation bias indicators
  confident_statement_words:
    - "clearly"
    - "obviously"
    - "definitely"
    - "certainly"
    - "undoubtedly"
    - "without question"
    - "absolutely"
  
  # Pattern over-generalization words
  pattern_generalization_words:
    - "always"
    - "never"
    - "all"
    - "every"
    - "none"
    - "completely"
    - "entirely"
  
  # Recency bias indicators
  recency_indicators:
    require_historical_context: true
    recent_focus_keywords:
      - "recent"
      - "lately"
      - "currently trending"
      - "modern"
    historical_balance_keywords:
      - "historical"
      - "traditionally"
      - "long-term"
      - "established"

# Hallucination detection patterns
hallucination_detection:
  # Content validation patterns
  line_reference_pattern: 'line\s+(\d+)'
  method_reference_pattern: '(?:function|method|class)\s+([a-zA-Z_][a-zA-Z0-9_]*)'
  technical_claims_pattern: '(?:will cause|results in|leads to|guarantees)\s+([^.!?]+)'
  
  # Contradiction detection
  contradiction_pairs:
    - ["high complexity", "low complexity"]
    - ["good quality", "poor quality"]
    - ["secure", "vulnerable"]
    - ["maintainable", "unmaintainable"]
    - ["efficient", "inefficient"]
    - ["scalable", "non-scalable"]
  
  # Validation thresholds
  max_method_references_warning: 5
  max_technical_claims_error: 3

# Context validation settings
context_validation:
  # Required context keywords for code analysis
  required_context_keywords:
    - "analysis"
    - "finding"
    - "code"
    - "file"
    - "issue"
    - "metric"
  
  # Evidence indicators
  evidence_indicators:
    - "analysis shows"
    - "data indicates"
    - "findings reveal"
    - "metrics demonstrate"
    - "code examination"
    - "line"
    - "function"
    - "method"
  
  # Uncertainty indicators
  uncertainty_indicators:
    - "might"
    - "could"
    - "possibly"
    - "perhaps"
    - "maybe"
    - "potentially"
    - "probably"
  
  # Reasoning indicators
  reasoning_indicators:
    - "because"
    - "therefore"
    - "due to"
    - "as a result"
    - "consequently"
    - "since"
    - "given that"

# Technical jargon detection
technical_jargon:
  # Excessive jargon patterns
  jargon_patterns:
    - "polymorphism"
    - "encapsulation"
    - "abstraction"
    - "instantiation"
    - "serialization"
    - "deserialization"
    - "parameterization"
  
  accessibility_requirements:
    avoid_excessive_jargon: true
    provide_definitions: true
    use_plain_language: true

# Bias prevention prompts
bias_prevention_prompts:
  # Cognitive bias prevention
  cognitive_bias:
    confirmation_bias_prompt: "\n\nIMPORTANT: Consider alternative perspectives and potential counterarguments to your analysis. Avoid confirmation bias by actively seeking evidence that might contradict your initial assessment."
    anchoring_bias_prompt: "\n\nAVOID ANCHORING: Don't over-rely on the first piece of information. Consider multiple viewpoints and re-evaluate your initial assumptions."
    availability_heuristic_prompt: "\n\nUSE STATISTICAL CONTEXT: Base analysis on complete data patterns, not just memorable or recent examples."
  
  # Technical bias prevention
  technical_bias:
    language_bias_prompt: "\n\nTECHNICAL OBJECTIVITY: Apply consistent quality standards regardless of programming language, framework, or technology stack. Base assessments on objective criteria, not personal preferences."
    framework_bias_prompt: "\n\nFRAMEWORK NEUTRALITY: Evaluate based on requirements and context, not personal technology preferences."
  
  # Contextual bias prevention
  contextual_bias:
    team_context_prompt: "\n\nCONTEXT AWARENESS: Consider the team's experience level, project constraints, and business context when making recommendations. Avoid one-size-fits-all solutions."
    industry_context_prompt: "\n\nINDUSTRY ADAPTATION: Adapt standards and recommendations to the specific industry and regulatory requirements."

# Response improvement settings
response_improvement:
  # Improvement prompts
  improvement_instructions:
    address_validation_errors: "1. Address all validation errors"
    provide_evidence: "2. Provide more specific evidence and references"
    include_reasoning: "3. Include reasoning for assessments"
    avoid_bias: "4. Avoid bias and unsupported claims"
    factual_grounding: "5. Be more factual and grounded in the provided data"
  
  # Quality enhancement
  quality_enhancement:
    system_prompt: "You are a quality-focused code analysis expert. Provide factual, evidence-based analysis with clear reasoning. Avoid bias and unsupported claims."
    temperature: 0.1
    focus_on_evidence: true
    require_reasoning: true

# Monitoring and feedback
monitoring:
  # Quality metrics tracking
  quality_metrics:
    track_confidence_scores: true
    track_evidence_scores: true
    track_validation_failures: true
    track_bias_indicators: true
    track_hallucination_indicators: true
  
  # Performance thresholds
  performance_thresholds:
    max_validation_failure_rate: 0.1
    min_average_confidence: 0.7
    min_average_evidence_score: 0.6
    max_bias_indicator_rate: 0.05
  
  # Logging settings
  logging:
    log_validation_results: true
    log_quality_metrics: true
    log_improvement_attempts: true
    detailed_failure_logging: true

# Fallback and error handling
error_handling:
  # Validation failure responses
  validation_failure_behavior: "fail_fast"  # Options: fail_fast, fallback, retry
  max_improvement_attempts: 1
  
  # Default scores for errors
  default_scores:
    confidence_score: 0.0
    evidence_score: 0.0
  
  # Error messages
  error_messages:
    validation_process_failed: "Validation process failed"
    insufficient_confidence: "Response confidence below threshold"
    insufficient_evidence: "Response lacks sufficient evidence"
    bias_detected: "Bias indicators detected in response"
    hallucination_detected: "Potential hallucination detected"