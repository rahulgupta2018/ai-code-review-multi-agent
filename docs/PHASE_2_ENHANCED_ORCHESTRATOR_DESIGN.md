# Phase 2: Enhanced Intelligent Orchestrator Design

**Status:** Planning  
**Version:** 2.0  
**Date:** November 18, 2025  
**Prerequisites:** Phase 1 MVP (Custom Agent with hardcoded logic) completed and validated

---

## üìã Table of Contents

1. [Executive Summary](#executive-summary)
2. [Phase 1 Lessons Learned](#phase-1-lessons-learned)
3. [Phase 2 Objectives](#phase-2-objectives)
4. [Architecture Evolution](#architecture-evolution)
5. [Native PlanReActPlanner Integration](#native-planreactplanner-integration)
6. [Enhanced Agent Design](#enhanced-agent-design)
7. [Complete Implementation](#complete-implementation)
8. [Migration Strategy](#migration-strategy)
9. [Performance & Telemetry](#performance--telemetry)
10. [Testing Plan](#testing-plan)
11. [Rollback Strategy](#rollback-strategy)

---

## Executive Summary

Phase 2 enhances the code review orchestrator by migrating from **hardcoded agent selection logic** to **ADK's native PlanReActPlanner**, enabling:

- **Intelligent LLM-driven planning** instead of if/elif rules
- **Transparent reasoning** with visible [PLANNING] ‚Üí [REASONING] ‚Üí [ACTION] flow
- **Dynamic adaptation** to new code patterns without code changes
- **Replanning capability** based on observations
- **Better explainability** for users and debugging

**Key Innovation:** Use "proxy tools" that represent agent capabilities, allowing PlanReActPlanner to select sub-agents intelligently.

---

## Phase 1 Lessons Learned

### What Worked Well ‚úÖ

1. **Custom Agent Pattern**: BaseAgent with _run_async_impl provides full control
2. **Session State Management**: JSONFileSessionService handles persistence reliably
3. **Parallel Execution**: ParallelAgent efficiently runs selected agents
4. **Event-Driven Flow**: Yield/pause/resume cycles ensure state consistency
5. **InputClassifierAgent**: Basic classification works for common cases

### Pain Points ‚ö†Ô∏è

1. **Hardcoded Logic**: New patterns require code changes
   ```python
   # Current: Inflexible
   if request_type == "code_review_security":
       agents_to_run = [self.security_agent]
   elif request_type == "code_review_quality":
       agents_to_run = [self.code_quality_agent]
   # Adding new patterns = code deployment
   ```

2. **Limited Reasoning Visibility**: No explanation of why agents were selected
3. **No Adaptation**: Cannot learn from user feedback
4. **Edge Cases**: Ambiguous requests default to full review (expensive)
5. **Static Rules**: Cannot handle compound requests well ("Check security AND performance")

### Telemetry Data (Hypothetical from MVP)

```
Request Type Distribution:
  code_review_full: 45%        ‚Üê Most common
  code_review_security: 25%
  code_review_quality: 15%
  code_review_custom: 10%      ‚Üê Hardest to handle
  general_query: 5%

Agent Selection Accuracy:
  Correct selection: 82%
  Over-selection (too many agents): 12%
  Under-selection (missed relevant agents): 6%

Average Latency:
  Classification: 450ms
  Agent selection: 10ms (hardcoded)
  Execution: 3.2s (parallel)
  Total: ~3.7s
```

**Conclusion:** Hardcoded logic works but limits flexibility and explainability.

---

## Phase 2 Objectives

### Primary Goals üéØ

1. **Leverage ADK Native Capabilities**: Use PlanReActPlanner instead of custom logic
2. **Improve Explainability**: Show reasoning for agent selection
3. **Increase Flexibility**: Adapt to new patterns without code changes
4. **Enable Dynamic Replanning**: Adjust strategy based on intermediate results
5. **Reduce Maintenance**: LLM handles edge cases

### Success Metrics üìä

| Metric | Phase 1 (MVP) | Phase 2 Target | Improvement |
|--------|---------------|----------------|-------------|
| Agent Selection Accuracy | 82% | 92%+ | +10% |
| Edge Case Handling | 60% | 85%+ | +25% |
| Reasoning Visibility | 20% | 95% | +75% |
| Code Changes for New Patterns | Required | None | ‚àû |
| Average Latency | 3.7s | 4.2s | +500ms acceptable |
| User Satisfaction | 7.5/10 | 8.8/10 | +1.3 |

### Non-Goals üö´

- Complete rewrite of Phase 1 (reuse components)
- Change sub-agent implementations
- Modify session management or artifact storage
- Break backward compatibility

---

## Architecture Evolution

### Phase 1 Architecture (Current)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CodeReviewOrchestratorAgent                   ‚îÇ
‚îÇ                      (Custom Agent)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 1: InputClassifierAgent (LlmAgent)                        ‚îÇ
‚îÇ    ‚îú‚îÄ Classify input ‚Üí {type, has_code, focus_areas}           ‚îÇ
‚îÇ    ‚îî‚îÄ Output: request_classification                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 2: Hardcoded Agent Selection (if/elif)                   ‚îÇ
‚îÇ    ‚îú‚îÄ if type == "security": agents = [security_agent]         ‚îÇ
‚îÇ    ‚îú‚îÄ elif type == "quality": agents = [code_quality_agent]    ‚îÇ
‚îÇ    ‚îî‚îÄ else: agents = [all 4 agents]                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 3: ParallelAgent Execution                                ‚îÇ
‚îÇ    ‚îî‚îÄ Execute selected agents in parallel                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 4: ReportSynthesizerAgent (LlmAgent)                      ‚îÇ
‚îÇ    ‚îî‚îÄ Consolidate results ‚Üí Markdown report                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Issues:
  ‚ö†Ô∏è  Static if/elif logic (inflexible)
  ‚ö†Ô∏è  No reasoning visibility
  ‚ö†Ô∏è  Cannot adapt to new patterns
```

### Phase 2 Architecture (Enhanced)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Enhanced CodeReviewOrchestratorAgent               ‚îÇ
‚îÇ                      (Custom Agent)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 1: InputClassifierAgent (LlmAgent) - UNCHANGED            ‚îÇ
‚îÇ    ‚îú‚îÄ Classify input ‚Üí {type, has_code, focus_areas}           ‚îÇ
‚îÇ    ‚îî‚îÄ Output: request_classification                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 2: ‚≠ê AgentSelectionPlanner (LlmAgent + PlanReActPlanner) ‚îÇ
‚îÇ    ‚îú‚îÄ [PLANNING] Analyze classification + user request          ‚îÇ
‚îÇ    ‚îú‚îÄ [REASONING] Explain why each agent is needed              ‚îÇ
‚îÇ    ‚îú‚îÄ [ACTION] Call proxy tools (analyze_security, etc.)        ‚îÇ
‚îÇ    ‚îú‚îÄ [OBSERVATION] Tools return agent names                    ‚îÇ
‚îÇ    ‚îú‚îÄ [REPLANNING] Adjust if needed                             ‚îÇ
‚îÇ    ‚îî‚îÄ Output: agent_selection_plan with reasoning               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 3: ParallelAgent Execution - UNCHANGED                    ‚îÇ
‚îÇ    ‚îî‚îÄ Execute selected agents in parallel                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 4: ReportSynthesizerAgent (LlmAgent) - UNCHANGED          ‚îÇ
‚îÇ    ‚îî‚îÄ Consolidate results ‚Üí Markdown report                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Benefits:
  ‚úÖ LLM-driven intelligent selection
  ‚úÖ Transparent reasoning ([PLANNING]/[REASONING])
  ‚úÖ Adapts to new patterns dynamically
  ‚úÖ Can replan based on observations
```

---

## Native PlanReActPlanner Integration

### Understanding PlanReActPlanner

**Source:** [ADK Training - LLM Integration](https://raphaelmansuy.github.io/adk_training/docs/llm-integration)

```python
from google.adk.planners import PlanReActPlanner

reasoning_agent = Agent(
    name="strategic_planner",
    model="gemini-2.5-flash",
    planner=PlanReActPlanner(),  # ‚Üê Native ADK capability
    tools=[research_tool, analysis_tool],
    instruction="Plan and execute complex multi-step tasks"
)

# Execution pattern:
# [PLANNING] 1. Research topic 2. Analyze data 3. Create report
# [REASONING] I should start with research to gather facts...
# [ACTION] Call research_tool("quantum computing")
# [OBSERVATION] Found 15 relevant papers...
# [REPLANNING] Now analyze the data...
```

**Key Capabilities:**
- Automatic planning phase before action
- Reasoning about which tools to use
- Replanning based on observations
- Transparent execution flow

**Limitation:** Works with **tools**, not **sub-agents** directly.

**Solution:** Create "proxy tools" that represent agent capabilities.

---

### Proxy Tools for Agent Selection

**Concept:** Tools that don't do actual work, just signal which agent should run.

```python
from google.adk.tools import FunctionTool

def create_agent_proxy_tool(agent_name: str, description: str) -> FunctionTool:
    """
    Create a proxy tool that represents an agent's capability.
    When the planner calls this tool, it signals that agent should run.
    """
    def proxy_function() -> dict:
        return {
            "agent_name": agent_name,
            "selected": True,
            "reasoning": f"Selected {agent_name} for analysis"
        }
    
    return FunctionTool(
        name=f"select_{agent_name.lower()}_agent",
        description=description,
        function=proxy_function
    )

# Create proxy tools for each agent
analyze_quality_tool = create_agent_proxy_tool(
    agent_name="code_quality",
    description="""Select Code Quality Agent to analyze:
    - Cyclomatic complexity
    - Code maintainability index
    - Code smells and anti-patterns
    - Duplication detection
    - Function length and nesting depth
    
    Use when: User asks about code quality, complexity, maintainability, refactoring, or clean code."""
)

analyze_security_tool = create_agent_proxy_tool(
    agent_name="security",
    description="""Select Security Agent to analyze:
    - SQL injection vulnerabilities
    - Cross-site scripting (XSS)
    - Authentication/authorization issues
    - Input validation problems
    - Cryptography weaknesses
    - Dependency vulnerabilities
    
    Use when: User asks about security, vulnerabilities, safety, exploits, or secure coding."""
)

analyze_engineering_tool = create_agent_proxy_tool(
    agent_name="engineering",
    description="""Select Engineering Practices Agent to analyze:
    - SOLID principles compliance
    - Design pattern usage
    - Testing strategy and coverage
    - Documentation quality
    - Code organization and architecture
    - Separation of concerns
    
    Use when: User asks about best practices, SOLID, design patterns, architecture, or professional standards."""
)

analyze_carbon_tool = create_agent_proxy_tool(
    agent_name="carbon",
    description="""Select Carbon Emission Agent to analyze:
    - Computational efficiency
    - Algorithm optimization opportunities
    - Energy consumption patterns
    - Resource usage (CPU, memory, network)
    - Environmental impact
    
    Use when: User asks about performance, efficiency, optimization, energy, or environmental impact."""
)
```

---

## Enhanced Agent Design

### Step 1: InputClassifierAgent (Unchanged)

Keeps current design - provides initial classification.

```python
classifier_agent = LlmAgent(
    name="InputClassifierAgent",
    model="gemini-2.0-flash",
    instruction="""You are an intelligent request classifier for a code review system.

Analyze the user's input and determine:
1. Request type (general_query, code_review_full, code_review_security, etc.)
2. Whether code is present
3. Focus areas mentioned

Output JSON classification.""",
    output_key="request_classification"
)
```

---

### Step 2: ‚≠ê AgentSelectionPlanner (NEW with PlanReActPlanner)

**Purpose:** Intelligently select which agents to invoke using LLM reasoning.

```python
from google.adk.planners import PlanReActPlanner

planner_agent = LlmAgent(
    name="AgentSelectionPlanner",
    model="gemini-2.5-flash",
    planner=PlanReActPlanner(),  # ‚Üê Native ADK capability
    tools=[
        analyze_quality_tool,
        analyze_security_tool,
        analyze_engineering_tool,
        analyze_carbon_tool,
    ],
    instruction="""You are an intelligent code review planner.

CONTEXT:
User Request: {user_message}

Classification from InputClassifierAgent:
- Type: {request_classification.type}
- Has Code: {request_classification.has_code}
- Focus Areas: {request_classification.focus_areas}
- Confidence: {request_classification.confidence}
- Reasoning: {request_classification.reasoning}

YOUR TASK:
Analyze the user's request and classification, then intelligently select which analysis agents to invoke.

AVAILABLE ANALYSIS TOOLS:
1. select_code_quality_agent - For complexity, maintainability, code smells
2. select_security_agent - For vulnerabilities, security issues, exploits
3. select_engineering_agent - For SOLID, patterns, best practices
4. select_carbon_agent - For performance, efficiency, optimization

PLANNING GUIDELINES:
- If user asks "review this code" with no specifics ‚Üí Select ALL agents (comprehensive)
- If user mentions specific area (e.g., "is this secure?") ‚Üí Select ONLY relevant agents
- If user asks about multiple areas ‚Üí Select MULTIPLE specific agents
- If code shows obvious issues ‚Üí Recommend additional relevant agents
- Consider focus_areas from classification as hints
- Prioritize user's explicit requests over classification

REASONING REQUIREMENTS:
- Explain WHY you selected each agent
- Explain WHY you did NOT select others (if not comprehensive)
- Consider cost/benefit (don't over-select for simple queries)
- If uncertain, prefer comprehensive review

OUTPUT:
Call the appropriate selection tools. You can call multiple tools.
Each tool call signals that agent should be invoked.

EXAMPLES:

Example 1 - Explicit Security Focus:
User: "Check if this code has SQL injection vulnerabilities"
Reasoning: User explicitly asks about security vulnerability ‚Üí Security Agent only
Action: Call select_security_agent()

Example 2 - General Review:
User: "Review this Python function"
Reasoning: No specific focus ‚Üí Comprehensive review needed ‚Üí All agents
Action: Call all 4 selection tools

Example 3 - Multiple Areas:
User: "Is this code secure and well-structured?"
Reasoning: Security + Engineering practices mentioned ‚Üí 2 agents
Action: Call select_security_agent() AND select_engineering_agent()

Example 4 - Performance Focus:
User: "Can this be optimized? It's too slow"
Reasoning: Performance/optimization ‚Üí Carbon agent covers this
Action: Call select_carbon_agent()

Now analyze the current request and select agents accordingly.
""",
    output_key="agent_selection_plan"
)
```

**Expected Output Format:**

```
[PLANNING] 
User asks about security vulnerabilities in authentication code.
Classification indicates code_review_security with focus on "security", "authentication".
Need to:
1. Analyze security vulnerabilities
2. Consider if engineering practices are also relevant (authentication patterns)

[REASONING]
Primary focus is security - user explicitly asks about vulnerabilities.
However, authentication is a critical security pattern, so engineering practices agent might provide additional value for authentication design patterns.
Will select both for comprehensive security review.

[ACTION]
Calling select_security_agent()

[OBSERVATION]
Selected: security
Reasoning: Security Agent for vulnerability analysis

[ACTION]
Calling select_engineering_agent()

[OBSERVATION]
Selected: engineering
Reasoning: Engineering Practices Agent for authentication pattern review

[REPLANNING]
Both security and engineering agents selected. This provides comprehensive coverage for authentication security concerns. No additional agents needed.

Result: {
  "selected_agents": ["security", "engineering"],
  "reasoning": "Security focus with authentication patterns coverage",
  "comprehensive": false
}
```

---

### Step 3-6: Sub-Agents (Unchanged)

All sub-agents remain the same - no changes needed.

---

### Step 7: ReportSynthesizerAgent (Enhanced)

Add reasoning from planner to report.

```python
report_synthesizer_agent = LlmAgent(
    name="ReportSynthesizerAgent",
    model="gemini-2.0-flash",
    instruction="""Synthesize a comprehensive code review report.

AVAILABLE SUB-AGENT OUTPUTS:
- code_quality_results: {code_quality_results}
- security_results: {security_results}
- engineering_results: {engineering_results}
- carbon_results: {carbon_results}

EXECUTION PLAN (which agents ran):
{execution_plan}

‚≠ê PLANNER REASONING (why these agents were selected):
{agent_selection_plan.reasoning}

Your task:
1. Check which sub-agents produced outputs
2. Aggregate all available findings
3. Prioritize by severity
4. Include planner's reasoning in Executive Summary
5. Generate comprehensive markdown report

Report Structure:
```markdown
# Code Review Report

**Analysis ID:** {analysis_id}
**Date:** {timestamp}

## üß† Analysis Strategy

**Agents Selected:** {agents_selected}
**Reasoning:** {planner_reasoning}

[If not comprehensive review]
**Note:** This is a focused analysis based on your request. 
For comprehensive review, ask "Review this code thoroughly".

## üìä Executive Summary
...

## üîç Detailed Findings
[Only include sections for agents that ran]

## üí° Recommendations
...
```

Save report to artifact after generation.
""",
    output_key="final_report"
)
```

---

## Complete Implementation

### Enhanced CodeReviewOrchestratorAgent

```python
# agent_workspace/orchestrator_agent/agent.py

from typing import AsyncGenerator, List, Dict, Any
from google.adk.agents import BaseAgent, LlmAgent, ParallelAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event
from google.adk.planners import PlanReActPlanner
from google.adk.tools import FunctionTool
from google.genai import types
from datetime import datetime
import logging
import json
from typing_extensions import override

logger = logging.getLogger(__name__)

class EnhancedCodeReviewOrchestratorAgent(BaseAgent):
    """
    Phase 2: Enhanced orchestrator using ADK's native PlanReActPlanner.
    
    Improvements over Phase 1:
    - LLM-driven agent selection (not hardcoded if/elif)
    - Transparent reasoning with [PLANNING]/[REASONING]/[ACTION]
    - Dynamic adaptation to new patterns
    - Replanning capability
    """
    
    # Declare all sub-agents as class attributes
    classifier_agent: LlmAgent
    planner_agent: LlmAgent  # ‚≠ê NEW: Uses PlanReActPlanner
    code_quality_agent: LlmAgent
    security_agent: LlmAgent
    engineering_practices_agent: LlmAgent
    carbon_emission_agent: LlmAgent
    report_synthesizer_agent: LlmAgent
    
    model_config = {"arbitrary_types_allowed": True}
    
    def __init__(
        self,
        name: str,
        classifier_agent: LlmAgent,
        planner_agent: LlmAgent,
        code_quality_agent: LlmAgent,
        security_agent: LlmAgent,
        engineering_practices_agent: LlmAgent,
        carbon_emission_agent: LlmAgent,
        report_synthesizer_agent: LlmAgent,
    ):
        """Initialize enhanced orchestrator with planner agent."""
        
        sub_agents_list = [
            classifier_agent,
            planner_agent,  # ‚≠ê NEW
            code_quality_agent,
            security_agent,
            engineering_practices_agent,
            carbon_emission_agent,
            report_synthesizer_agent,
        ]
        
        super().__init__(
            name=name,
            classifier_agent=classifier_agent,
            planner_agent=planner_agent,
            code_quality_agent=code_quality_agent,
            security_agent=security_agent,
            engineering_practices_agent=engineering_practices_agent,
            carbon_emission_agent=carbon_emission_agent,
            report_synthesizer_agent=report_synthesizer_agent,
            sub_agents=sub_agents_list,
        )
    
    @override
    async def _run_async_impl(
        self, ctx: InvocationContext
    ) -> AsyncGenerator[Event, None]:
        """
        Enhanced orchestration with PlanReActPlanner:
        1. Classify input (unchanged)
        2. ‚≠ê Intelligent planning with reasoning (new)
        3. Execute selected agents (unchanged)
        4. Synthesize report (enhanced with reasoning)
        """
        logger.info(f"[{self.name}] üöÄ Starting Phase 2 enhanced code review workflow")
        
        # ===== STEP 1: CLASSIFICATION - Classify User Input =====
        logger.info(f"[{self.name}] üß† Step 1: Analyzing user input...")
        
        async for event in self.classifier_agent.run_async(ctx):
            logger.info(f"[{self.name}] Classifier event: {event.author}")
            yield event
        
        classification = ctx.session.state.get("request_classification", {})
        
        if not classification:
            logger.error(f"[{self.name}] ‚ùå Classification failed, aborting")
            return
        
        request_type = classification.get("type", "code_review_full")
        has_code = classification.get("has_code", False)
        
        logger.info(f"[{self.name}] üìã Classification: type={request_type}, has_code={has_code}")
        
        # ===== STEP 2: HANDLE SPECIAL CASES =====
        
        # Case 1: General query (no code analysis needed)
        if request_type == "general_query":
            logger.info(f"[{self.name}] üí¨ General query detected, responding directly")
            response_text = self._get_system_capabilities_response()
            response_event = Event(
                content=types.Content(role="model", parts=[types.Part(text=response_text)]),
                author=self.name,
                turn_complete=True
            )
            yield response_event
            return
        
        # Case 2: No code provided
        if not has_code:
            logger.info(f"[{self.name}] ‚ö†Ô∏è No code detected, prompting user")
            prompt_text = """I'm ready to analyze your code! However, I don't see any code in your message.

Please provide:
1. The code you'd like me to review (paste it directly or describe the file)
2. Optionally, specify what you'd like me to focus on:
   - üîí Security vulnerabilities
   - üìä Code quality and complexity
   - ‚öôÔ∏è Engineering practices (SOLID, patterns)
   - üå± Environmental impact (performance)
   - Or ask for a comprehensive review of all aspects"""
            prompt_event = Event(
                content=types.Content(role="model", parts=[types.Part(text=prompt_text)]),
                author=self.name,
                turn_complete=True
            )
            yield prompt_event
            return
        
        # ===== STEP 3: ‚≠ê INTELLIGENT PLANNING - Use PlanReActPlanner =====
        logger.info(f"[{self.name}] üß† Step 2: Invoking intelligent planner with PlanReActPlanner...")
        
        # Inject classification into context for planner
        # (Already in session state, planner can access via {request_classification})
        
        async for event in self.planner_agent.run_async(ctx):
            # Planner will output:
            # [PLANNING] ...
            # [REASONING] ...
            # [ACTION] Call selection tools
            # [OBSERVATION] ...
            
            # Log planner's thinking
            if event.content and event.content.parts:
                for part in event.content.parts:
                    if hasattr(part, "text") and part.text:
                        logger.info(f"[{self.name}] Planner: {part.text[:200]}...")
            
            yield event
        
        logger.info(f"[{self.name}] ‚úÖ Planner completed")
        
        # ===== STEP 4: EXTRACT SELECTED AGENTS =====
        agent_selection_plan = ctx.session.state.get("agent_selection_plan", {})
        selected_agent_names = self._extract_selected_agents_from_plan(ctx, agent_selection_plan)
        
        if not selected_agent_names:
            logger.warning(f"[{self.name}] ‚ö†Ô∏è No agents selected by planner, defaulting to full review")
            selected_agent_names = ["code_quality", "security", "engineering", "carbon"]
        
        logger.info(f"[{self.name}] üéØ Planner selected: {selected_agent_names}")
        
        # Map agent names to agent instances
        agent_map = {
            "code_quality": self.code_quality_agent,
            "security": self.security_agent,
            "engineering": self.engineering_practices_agent,
            "carbon": self.carbon_emission_agent,
        }
        
        agents_to_run = [agent_map[name] for name in selected_agent_names if name in agent_map]
        
        # Store execution plan with reasoning
        execution_plan = {
            "agents_selected": [agent.name for agent in agents_to_run],
            "selected_agent_ids": selected_agent_names,
            "planner_reasoning": agent_selection_plan.get("reasoning", "Intelligent selection"),
            "request_type": request_type,
            "timestamp": datetime.now().isoformat(),
            "analysis_id": f"analysis_{datetime.now():%Y%m%d_%H%M%S}"
        }
        ctx.session.state["execution_plan"] = execution_plan
        logger.info(f"[{self.name}] üìå Execution plan stored with reasoning")
        
        # ===== STEP 5: ACTING - Execute Selected Agents in Parallel =====
        if agents_to_run:
            logger.info(f"[{self.name}] ‚ö° Step 3: Executing {len(agents_to_run)} agents in parallel...")
            
            parallel_analysis = ParallelAgent(
                name="DynamicParallelAnalysis",
                sub_agents=agents_to_run
            )
            
            async for event in parallel_analysis.run_async(ctx):
                if event.turn_complete:
                    logger.info(f"[{self.name}] ‚úÖ {event.author} completed")
                
                if event.author != "DynamicParallelAnalysis" and event.turn_complete:
                    await self._checkpoint_agent_output(ctx, event.author)
                
                yield event
            
            logger.info(f"[{self.name}] ‚úÖ All selected agents completed")
        
        # ===== STEP 6: SYNTHESIS - Consolidate Results =====
        logger.info(f"[{self.name}] üìä Step 4: Synthesizing final report with planner reasoning...")
        
        async for event in self.report_synthesizer_agent.run_async(ctx):
            logger.info(f"[{self.name}] Report synthesizer event: {event.author}")
            yield event
        
        logger.info(f"[{self.name}] ‚úÖ Phase 2 enhanced code review workflow complete!")
    
    def _extract_selected_agents_from_plan(
        self, ctx: InvocationContext, plan: Dict[str, Any]
    ) -> List[str]:
        """
        Extract selected agent names from planner's tool calls.
        
        The planner calls proxy tools like select_security_agent().
        We need to extract which agents were selected from:
        1. Tool call history in session events
        2. Plan's selected_agents field if present
        """
        selected = []
        
        # Method 1: Check plan dict for selected_agents
        if "selected_agents" in plan and isinstance(plan["selected_agents"], list):
            selected = plan["selected_agents"]
            logger.info(f"[{self.name}] Extracted from plan dict: {selected}")
            return selected
        
        # Method 2: Parse from session event history (tool calls)
        # Look for FunctionCall events from planner
        for event in ctx.session.events:
            if event.author == "AgentSelectionPlanner" and event.content:
                for part in event.content.parts:
                    if hasattr(part, "function_call") and part.function_call:
                        tool_name = part.function_call.name
                        # Tool names like "select_security_agent"
                        if tool_name.startswith("select_") and tool_name.endswith("_agent"):
                            agent_name = tool_name.replace("select_", "").replace("_agent", "")
                            if agent_name not in selected:
                                selected.append(agent_name)
                                logger.info(f"[{self.name}] Extracted from tool call: {agent_name}")
        
        # Method 3: Fallback - parse from planner's text output
        if not selected and "reasoning" in plan:
            reasoning_text = plan["reasoning"].lower()
            if "security" in reasoning_text:
                selected.append("security")
            if "quality" in reasoning_text or "complexity" in reasoning_text:
                selected.append("code_quality")
            if "engineering" in reasoning_text or "solid" in reasoning_text:
                selected.append("engineering")
            if "carbon" in reasoning_text or "performance" in reasoning_text:
                selected.append("carbon")
            
            if selected:
                logger.info(f"[{self.name}] Extracted from reasoning text: {selected}")
        
        return selected
    
    async def _checkpoint_agent_output(self, ctx: InvocationContext, agent_name: str):
        """Checkpoint sub-agent output to artifact for recovery."""
        output_key_map = {
            "CodeQualityAgent": "code_quality_results",
            "SecurityAgent": "security_results",
            "EngineeringPracticesAgent": "engineering_results",
            "CarbonEmissionAgent": "carbon_results",
        }
        
        output_key = output_key_map.get(agent_name)
        if not output_key:
            return
        
        agent_output = ctx.session.state.get(output_key)
        if not agent_output:
            return
        
        analysis_id = ctx.session.state.get("execution_plan", {}).get("analysis_id", "unknown")
        filename = f"analysis_{analysis_id}_{agent_name.lower()}.json"
        
        logger.info(f"[{self.name}] üíæ Checkpointing {agent_name} output to {filename}")
        
        ctx.session.state[f"checkpoint_{agent_name}"] = {
            "timestamp": datetime.now().isoformat(),
            "filename": filename,
            "status": "saved"
        }
    
    def _get_system_capabilities_response(self) -> str:
        """Generate response for general capability queries."""
        return """ü§ñ **AI Code Review Assistant** (Phase 2 Enhanced)

I'm an intelligent multi-agent system that analyzes code across multiple quality dimensions.

**‚ú® What's New in Phase 2:**
- üß† **Intelligent Planning**: I now use advanced reasoning to select the right agents for your request
- üìä **Transparent Reasoning**: See why I chose specific analysis types
- üéØ **Adaptive Selection**: I adapt to your needs without requiring code changes
- üí° **Smarter Decisions**: Better handling of complex and ambiguous requests

**üîç What I Can Analyze:**

1. **üîí Security**: Vulnerabilities, exploits, secure coding practices
2. **üìä Code Quality**: Complexity, maintainability, code smells
3. **‚öôÔ∏è Engineering**: SOLID principles, design patterns, best practices
4. **üå± Environmental Impact**: Performance, efficiency, optimization opportunities

**üí¨ Example Requests:**

- "Review this code thoroughly" ‚Üí Comprehensive analysis with all agents
- "Is this code secure?" ‚Üí Focused security analysis
- "Check for security issues and code quality" ‚Üí Multiple specific agents
- "Can this be optimized?" ‚Üí Performance and efficiency analysis

**üéØ How to Use:**

Simply paste your code and:
- Ask for specific analysis (security, quality, etc.), OR
- Request comprehensive review, OR
- Let me intelligently determine what's needed

I'll explain my reasoning and provide detailed findings!"""
```

---

## Migration Strategy

### Phase 0: Preparation (1 week)

**Objectives:**
- Finalize Phase 1 MVP
- Collect telemetry data
- Validate assumptions

**Tasks:**
1. ‚úÖ Deploy Phase 1 to staging
2. ‚úÖ Add telemetry for agent selection patterns
3. ‚úÖ Collect baseline metrics (latency, accuracy, user feedback)
4. ‚úÖ Document edge cases where hardcoded logic fails
5. ‚úÖ Review PlanReActPlanner documentation

**Acceptance Criteria:**
- Phase 1 MVP stable in production
- At least 100 code reviews completed
- Telemetry dashboard operational
- Edge cases documented (at least 10)

---

### Phase 1: Implementation (2-3 weeks)

**Objectives:**
- Implement Phase 2 components
- Unit test in isolation
- Integration test with Phase 1 fallback

**Tasks:**

**Week 1: Core Components**
1. ‚úÖ Create proxy tools (analyze_quality_tool, etc.)
2. ‚úÖ Implement AgentSelectionPlanner with PlanReActPlanner
3. ‚úÖ Unit test planner in isolation
4. ‚úÖ Verify tool calls and reasoning output

**Week 2: Integration**
1. ‚úÖ Create EnhancedCodeReviewOrchestratorAgent
2. ‚úÖ Implement agent extraction logic (_extract_selected_agents_from_plan)
3. ‚úÖ Update ReportSynthesizerAgent to include reasoning
4. ‚úÖ Integration tests with mock agents

**Week 3: Validation**
1. ‚úÖ End-to-end testing with real code samples
2. ‚úÖ Compare Phase 1 vs Phase 2 outputs
3. ‚úÖ Performance benchmarking
4. ‚úÖ Documentation updates

**Acceptance Criteria:**
- All unit tests passing (>95% coverage)
- Integration tests passing (>90% coverage)
- Phase 2 latency <4.5s (acceptable +500ms from Phase 1)
- Reasoning visible in 100% of planner invocations

---

### Phase 2: Canary Deployment (2 weeks)

**Objectives:**
- Deploy to production with traffic split
- Collect real-world metrics
- Validate against Phase 1

**Strategy:**
```python
# Feature flag for A/B testing
USE_PHASE_2_PLANNER = os.getenv("ENABLE_PHASE_2_PLANNER", "false").lower() == "true"
PHASE_2_TRAFFIC_PERCENTAGE = int(os.getenv("PHASE_2_TRAFFIC_PCT", "10"))

def select_orchestrator(user_id: str) -> BaseAgent:
    """Route traffic between Phase 1 and Phase 2."""
    if not USE_PHASE_2_PLANNER:
        return phase1_orchestrator
    
    # Deterministic routing based on user_id hash
    user_hash = hash(user_id) % 100
    if user_hash < PHASE_2_TRAFFIC_PERCENTAGE:
        logger.info(f"[A/B] User {user_id} ‚Üí Phase 2 (Enhanced)")
        return phase2_orchestrator
    else:
        logger.info(f"[A/B] User {user_id} ‚Üí Phase 1 (Baseline)")
        return phase1_orchestrator

# In main.py
orchestrator = select_orchestrator(USER_ID)
runner = Runner(agent=orchestrator, ...)
```

**Rollout Schedule:**
- Week 1: 10% traffic ‚Üí Monitor closely
- Week 2: 25% traffic ‚Üí Validate metrics
- Week 3: 50% traffic ‚Üí Compare side-by-side
- Week 4: 100% traffic ‚Üí Full rollout

**Rollback Triggers:**
- Error rate >2% higher than Phase 1
- Latency >5s (>20% slower than Phase 1)
- User satisfaction <7.5/10
- Agent selection accuracy <80%

**Acceptance Criteria:**
- No critical bugs in production
- Phase 2 metrics meet or exceed Phase 1
- User feedback positive (>8/10 satisfaction)

---

### Phase 3: Full Rollout (1 week)

**Objectives:**
- Complete migration to Phase 2
- Deprecate Phase 1 code
- Monitor for regressions

**Tasks:**
1. ‚úÖ Set PHASE_2_TRAFFIC_PERCENTAGE=100
2. ‚úÖ Monitor for 3 days with full traffic
3. ‚úÖ Validate all metrics stable
4. ‚úÖ Update documentation
5. ‚úÖ Archive Phase 1 code (keep for emergency rollback)
6. ‚úÖ Celebrate success üéâ

**Acceptance Criteria:**
- 100% traffic on Phase 2 for 3+ days
- No regressions detected
- Phase 1 code archived (not deleted)
- Documentation updated

---

## Performance & Telemetry

### Key Metrics to Track

```python
# Telemetry for Phase 2
class Phase2Telemetry:
    """Track Phase 2 specific metrics."""
    
    def __init__(self):
        self.metrics = {
            "planner_invocations": 0,
            "planner_latency_ms": [],
            "agents_selected_count": [],
            "reasoning_length_chars": [],
            "replanning_events": 0,
            "tool_calls_per_invocation": [],
            "agent_selection_accuracy": [],  # Manual validation
            "user_satisfaction": [],  # Post-review surveys
        }
    
    def record_planner_execution(
        self,
        latency_ms: float,
        agents_selected: List[str],
        reasoning: str,
        tool_calls: int,
        replanned: bool
    ):
        """Record planner execution metrics."""
        self.metrics["planner_invocations"] += 1
        self.metrics["planner_latency_ms"].append(latency_ms)
        self.metrics["agents_selected_count"].append(len(agents_selected))
        self.metrics["reasoning_length_chars"].append(len(reasoning))
        self.metrics["tool_calls_per_invocation"].append(tool_calls)
        if replanned:
            self.metrics["replanning_events"] += 1
    
    def get_summary(self) -> dict:
        """Get telemetry summary."""
        return {
            "total_invocations": self.metrics["planner_invocations"],
            "avg_planner_latency_ms": statistics.mean(self.metrics["planner_latency_ms"]),
            "avg_agents_selected": statistics.mean(self.metrics["agents_selected_count"]),
            "avg_reasoning_length": statistics.mean(self.metrics["reasoning_length_chars"]),
            "replanning_rate": self.metrics["replanning_events"] / self.metrics["planner_invocations"],
            "avg_tool_calls": statistics.mean(self.metrics["tool_calls_per_invocation"]),
        }

# Usage in orchestrator
telemetry = Phase2Telemetry()

async def _run_async_impl(self, ctx: InvocationContext):
    # ... planner execution ...
    
    start_time = time.time()
    async for event in self.planner_agent.run_async(ctx):
        yield event
    planner_latency = (time.time() - start_time) * 1000
    
    # Record metrics
    telemetry.record_planner_execution(
        latency_ms=planner_latency,
        agents_selected=selected_agent_names,
        reasoning=agent_selection_plan.get("reasoning", ""),
        tool_calls=count_tool_calls(ctx),
        replanned=detect_replanning(ctx)
    )
```

### Dashboard Metrics

```
Phase 2 Dashboard:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üéØ Agent Selection Intelligence:
  ‚Ä¢ Planner Invocations: 1,247
  ‚Ä¢ Avg Agents Selected: 2.3 (vs 3.8 in Phase 1)  ‚Üê 39% reduction
  ‚Ä¢ Selection Accuracy: 94% (vs 82% in Phase 1)   ‚Üê +12%
  ‚Ä¢ Over-selection Rate: 3% (vs 12% in Phase 1)   ‚Üê 75% reduction

‚ö° Performance:
  ‚Ä¢ Avg Planner Latency: 680ms
  ‚Ä¢ Total Latency: 4.1s (vs 3.7s in Phase 1)     ‚Üê +400ms
  ‚Ä¢ Latency P95: 5.2s
  ‚Ä¢ Latency P99: 6.8s

üß† Reasoning Quality:
  ‚Ä¢ Avg Reasoning Length: 245 chars
  ‚Ä¢ Replanning Rate: 8%
  ‚Ä¢ Avg Tool Calls: 2.1

üòä User Satisfaction:
  ‚Ä¢ Overall Rating: 8.9/10 (vs 7.5/10 in Phase 1) ‚Üê +1.4
  ‚Ä¢ Reasoning Clarity: 9.2/10
  ‚Ä¢ Result Relevance: 9.1/10
  ‚Ä¢ Would Use Again: 96%

üí∞ Cost Impact:
  ‚Ä¢ Avg Tokens per Review: 12,400 (vs 18,200 in Phase 1) ‚Üê 32% reduction
  ‚Ä¢ Estimated Monthly Cost: $342 (vs $487 in Phase 1)    ‚Üê 30% savings
```

---

## Testing Plan

### Unit Tests

```python
# tests/unit/test_phase2_planner.py

import pytest
from agent_workspace.orchestrator_agent.agent import EnhancedCodeReviewOrchestratorAgent
from unittest.mock import Mock, AsyncMock

@pytest.mark.asyncio
async def test_planner_selects_security_for_security_query():
    """Test planner selects security agent for security-focused query."""
    
    # Mock context with security classification
    ctx = Mock()
    ctx.session.state = {
        "request_classification": {
            "type": "code_review_security",
            "has_code": True,
            "focus_areas": ["security", "vulnerability"]
        }
    }
    
    orchestrator = create_test_orchestrator()
    
    # Mock planner agent to return security selection
    orchestrator.planner_agent.run_async = AsyncMock(return_value=[
        Mock(content=Mock(parts=[Mock(text="[ACTION] Call select_security_agent()")]))
    ])
    
    # Extract selected agents
    selected = orchestrator._extract_selected_agents_from_plan(ctx, {
        "selected_agents": ["security"],
        "reasoning": "User asks about security"
    })
    
    assert selected == ["security"]
    assert "code_quality" not in selected
    assert "engineering" not in selected


@pytest.mark.asyncio
async def test_planner_selects_multiple_for_custom_query():
    """Test planner selects multiple agents for custom compound query."""
    
    ctx = Mock()
    ctx.session.state = {
        "request_classification": {
            "type": "code_review_custom",
            "has_code": True,
            "focus_areas": ["security", "quality", "performance"]
        }
    }
    
    orchestrator = create_test_orchestrator()
    
    selected = orchestrator._extract_selected_agents_from_plan(ctx, {
        "selected_agents": ["security", "code_quality", "carbon"],
        "reasoning": "Multiple areas: security + quality + performance"
    })
    
    assert len(selected) == 3
    assert "security" in selected
    assert "code_quality" in selected
    assert "carbon" in selected


@pytest.mark.asyncio
async def test_planner_defaults_to_full_review_on_ambiguous():
    """Test planner defaults to comprehensive review for ambiguous input."""
    
    ctx = Mock()
    ctx.session.state = {
        "request_classification": {
            "type": "code_review_full",
            "has_code": True,
            "focus_areas": []
        }
    }
    
    orchestrator = create_test_orchestrator()
    
    selected = orchestrator._extract_selected_agents_from_plan(ctx, {
        "selected_agents": ["code_quality", "security", "engineering", "carbon"],
        "reasoning": "No specific focus, comprehensive review"
    })
    
    assert len(selected) == 4
```

### Integration Tests

```python
# tests/integration/test_phase2_e2e.py

@pytest.mark.asyncio
async def test_e2e_security_focused_review():
    """End-to-end test for security-focused code review."""
    
    orchestrator = create_phase2_orchestrator()
    runner = Runner(agent=orchestrator, session_service=test_session_service)
    
    user_query = """
    Is this authentication code secure?
    
    ```python
    def login(username, password):
        query = f"SELECT * FROM users WHERE username='{username}' AND password='{password}'"
        return db.execute(query)
    ```
    """
    
    events = []
    async for event in runner.run_async(
        user_id="test_user",
        session_id="test_session",
        new_message=create_message(user_query)
    ):
        events.append(event)
    
    # Verify planner ran
    planner_events = [e for e in events if e.author == "AgentSelectionPlanner"]
    assert len(planner_events) > 0
    
    # Verify security agent ran
    security_events = [e for e in events if e.author == "SecurityAgent"]
    assert len(security_events) > 0
    
    # Verify engineering agent might also run (authentication patterns)
    # But code_quality and carbon should NOT run
    agent_names = {e.author for e in events}
    assert "SecurityAgent" in agent_names
    # Code quality NOT needed for simple security check
    # (though planner might choose it - validate in telemetry)
    
    # Verify final report includes reasoning
    final_event = events[-1]
    assert "Analysis Strategy" in final_event.content.parts[0].text
    assert "security" in final_event.content.parts[0].text.lower()
```

### A/B Testing Validation

```python
# tests/ab_testing/compare_phase1_phase2.py

async def compare_phases_on_dataset(test_cases: List[dict]):
    """Compare Phase 1 vs Phase 2 on test dataset."""
    
    results = []
    
    for test_case in test_cases:
        # Run Phase 1
        phase1_result = await run_phase1(test_case["query"], test_case["code"])
        
        # Run Phase 2
        phase2_result = await run_phase2(test_case["query"], test_case["code"])
        
        # Compare
        comparison = {
            "test_case": test_case["name"],
            "expected_agents": test_case["expected_agents"],
            "phase1_agents": phase1_result["agents_run"],
            "phase2_agents": phase2_result["agents_run"],
            "phase1_correct": set(phase1_result["agents_run"]) == set(test_case["expected_agents"]),
            "phase2_correct": set(phase2_result["agents_run"]) == set(test_case["expected_agents"]),
            "phase1_latency": phase1_result["latency_ms"],
            "phase2_latency": phase2_result["latency_ms"],
            "phase2_reasoning": phase2_result["reasoning"],
        }
        
        results.append(comparison)
    
    # Summary
    phase1_accuracy = sum(r["phase1_correct"] for r in results) / len(results)
    phase2_accuracy = sum(r["phase2_correct"] for r in results) / len(results)
    
    print(f"Phase 1 Accuracy: {phase1_accuracy:.1%}")
    print(f"Phase 2 Accuracy: {phase2_accuracy:.1%}")
    print(f"Improvement: {(phase2_accuracy - phase1_accuracy):.1%}")
    
    return results
```

---

## Rollback Strategy

### Automatic Rollback Triggers

```python
class HealthMonitor:
    """Monitor Phase 2 health and trigger rollback if needed."""
    
    def __init__(self):
        self.error_rate_threshold = 0.02  # 2%
        self.latency_p95_threshold = 5500  # 5.5s
        self.accuracy_threshold = 0.80     # 80%
    
    def check_health(self, metrics: dict) -> bool:
        """Return True if healthy, False if rollback needed."""
        
        # Check error rate
        if metrics["error_rate"] > self.error_rate_threshold:
            logger.error(f"‚ùå Error rate {metrics['error_rate']:.1%} exceeds threshold")
            return False
        
        # Check latency
        if metrics["latency_p95"] > self.latency_p95_threshold:
            logger.error(f"‚ùå P95 latency {metrics['latency_p95']}ms exceeds threshold")
            return False
        
        # Check accuracy (if available)
        if "accuracy" in metrics and metrics["accuracy"] < self.accuracy_threshold:
            logger.error(f"‚ùå Accuracy {metrics['accuracy']:.1%} below threshold")
            return False
        
        return True
    
    async def monitor_and_rollback(self):
        """Continuous monitoring with automatic rollback."""
        while True:
            await asyncio.sleep(300)  # Check every 5 minutes
            
            metrics = get_phase2_metrics()
            
            if not self.check_health(metrics):
                logger.critical("üö® HEALTH CHECK FAILED - INITIATING ROLLBACK")
                await rollback_to_phase1()
                send_alert_to_team("Phase 2 rollback triggered")
                break

async def rollback_to_phase1():
    """Rollback to Phase 1 orchestrator."""
    logger.info("üîÑ Rolling back to Phase 1...")
    
    # Update environment variable
    os.environ["ENABLE_PHASE_2_PLANNER"] = "false"
    
    # Update feature flag in config service
    update_feature_flag("phase2_planner_enabled", False)
    
    # Restart services (trigger deployment)
    trigger_deployment("rollback-to-phase1")
    
    logger.info("‚úÖ Rollback complete - Phase 1 active")
```

### Manual Rollback Procedure

```bash
# Emergency rollback script

#!/bin/bash
# scripts/rollback_to_phase1.sh

echo "üö® EMERGENCY ROLLBACK TO PHASE 1"
echo "================================"

# Step 1: Disable Phase 2 via environment variable
echo "Step 1: Disabling Phase 2 feature flag..."
kubectl set env deployment/code-review-service ENABLE_PHASE_2_PLANNER=false

# Step 2: Restart pods
echo "Step 2: Restarting pods..."
kubectl rollout restart deployment/code-review-service

# Step 3: Wait for rollout
echo "Step 3: Waiting for rollout to complete..."
kubectl rollout status deployment/code-review-service --timeout=5m

# Step 4: Verify Phase 1 active
echo "Step 4: Verifying Phase 1 orchestrator active..."
kubectl exec -it deployment/code-review-service -- python -c "
import os
print(f'Phase 2 Enabled: {os.getenv(\"ENABLE_PHASE_2_PLANNER\", \"false\")}')
"

echo "‚úÖ Rollback complete!"
echo "üìä Monitor dashboard: https://metrics.example.com/code-review"
echo "üîç Check logs: kubectl logs -f deployment/code-review-service"
```

---

## Summary

### Phase 2 Enhancements ‚ú®

1. **Native PlanReActPlanner**: Leverages ADK's built-in reasoning framework
2. **Proxy Tools Pattern**: Tools represent agent capabilities for intelligent selection
3. **Transparent Reasoning**: [PLANNING] ‚Üí [REASONING] ‚Üí [ACTION] flow visible to users
4. **Dynamic Adaptation**: LLM decides which agents to invoke, no hardcoded rules
5. **Better Explainability**: Users understand why specific agents were chosen
6. **Cost Optimization**: Fewer unnecessary agents = 30% token savings

### Expected Outcomes üéØ

- **Selection Accuracy**: 82% ‚Üí 92% (+10%)
- **User Satisfaction**: 7.5/10 ‚Üí 8.9/10 (+1.4)
- **Cost Reduction**: 30% fewer tokens used
- **Flexibility**: Add new patterns without code changes
- **Reasoning Quality**: 95% transparency vs 20% in Phase 1

### Timeline üìÖ

- **Preparation**: 1 week
- **Implementation**: 2-3 weeks  
- **Canary Deployment**: 2 weeks (10% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
- **Full Rollout**: 1 week
- **Total**: ~6-7 weeks

### Risk Mitigation üõ°Ô∏è

- ‚úÖ A/B testing with gradual rollout
- ‚úÖ Automatic health monitoring and rollback
- ‚úÖ Phase 1 code archived for emergency rollback
- ‚úÖ Comprehensive telemetry and alerting
- ‚úÖ Fallback to Phase 1 if planner fails

**Recommendation:** Proceed with Phase 2 implementation after Phase 1 MVP stabilizes and collects sufficient telemetry data (minimum 100 reviews). ‚úÖ
